{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014282,
     "end_time": "2023-06-03T01:46:16.695936",
     "exception": false,
     "start_time": "2023-06-03T01:46:16.681654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-24T09:43:44.600967Z",
     "iopub.status.busy": "2023-09-24T09:43:44.600229Z",
     "iopub.status.idle": "2023-09-24T09:43:50.495944Z",
     "shell.execute_reply": "2023-09-24T09:43:50.494498Z",
     "shell.execute_reply.started": "2023-09-24T09:43:44.600930Z"
    },
    "papermill": {
     "duration": 4.795021,
     "end_time": "2023-06-03T01:46:36.791162",
     "exception": false,
     "start_time": "2023-06-03T01:46:31.996141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly_express as px\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import early_stopping,log_evaluation, LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "set_config(transform_output = 'pandas')\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-24T09:43:50.500527Z",
     "iopub.status.busy": "2023-09-24T09:43:50.499127Z",
     "iopub.status.idle": "2023-09-24T09:44:16.378234Z",
     "shell.execute_reply": "2023-09-24T09:44:16.376885Z",
     "shell.execute_reply.started": "2023-09-24T09:43:50.500463Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit(10)\n",
    "\n",
    "def cross_val_score(estimatorConstructor,X,y, cv = tss, label = ''):\n",
    "\n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics   \n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = estimatorConstructor()\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        mu = X_train.mean()\n",
    "        X_train.fillna(mu)\n",
    "        X_val.fillna(mu)\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train,(X_val,y_val))\n",
    "        \n",
    "        #make predictions\n",
    "        # train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        # train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        print(\"Fold\",fold,\"Val MAE:\",val_score)\n",
    "        \n",
    "        # append model score for a fold to list\n",
    "        # train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} Â± {np.std(val_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T09:44:44.962033Z",
     "iopub.status.busy": "2023-09-24T09:44:44.961514Z",
     "iopub.status.idle": "2023-09-24T09:44:44.977754Z",
     "shell.execute_reply": "2023-09-24T09:44:44.976315Z",
     "shell.execute_reply.started": "2023-09-24T09:44:44.961984Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "class MetaModel: \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.config = {\n",
    "            \"nb_round_early_stop\":100\n",
    "        }\n",
    "        \n",
    "        self.firstLayerMethods = [\n",
    "            {\n",
    "                \"type\":\"LGBMR\",\n",
    "                \"model\":LGBMRegressor(**{\n",
    "                        'device': \"cpu\",\n",
    "                        'objective'         : 'regression_l1',\n",
    "                        'boosting_type'     : 'gbdt',\n",
    "                        'random_state'      : 42,\n",
    "                        'colsample_bytree'  : 0.7,\n",
    "                        'subsample'         : 0.65,\n",
    "                        'learning_rate'     : 0.065,\n",
    "                        'max_depth'         : 6,\n",
    "                        'n_estimators'      : 500,\n",
    "                        'num_leaves'        : 150,  \n",
    "                        'reg_alpha'         : 0.01,\n",
    "                        'reg_lambda'        : 3.25,\n",
    "                        'verbose'           : -1,\n",
    "                       })\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"catboost\",\n",
    "                \"model\":CatBoostRegressor(**{\n",
    "                    'task_type': \"CPU\",\n",
    "                    'objective'           : \"MAE\",\n",
    "                    'eval_metric'         : \"MAE\",\n",
    "                    'bagging_temperature' : 0.5,\n",
    "                    'colsample_bylevel'   : 0.7,\n",
    "                    'iterations'          : 500,\n",
    "                    'learning_rate'       : 0.065,\n",
    "                    'od_wait'             : 25,\n",
    "                    'max_depth'           : 7,\n",
    "                    'l2_leaf_reg'         : 1.5,\n",
    "                    'min_data_in_leaf'    : 1000,\n",
    "                    'random_strength'     : 0.65, \n",
    "                    'verbose'             : 0,\n",
    "                    'use_best_model'      : True,\n",
    "                  })\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        self.firstLayerSelectionEncoder = OneHotEncoder(sparse_output=False)\n",
    "        \n",
    "        self.firstLayerSelector = CatBoostClassifier(random_seed=seed,objective=\"MultiLogloss\", n_estimators=100, verbose=0)\n",
    "        \n",
    "        # self.reg = LinearRegression()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fit(self,X,y,eval_set=None):\n",
    "        firstLayerPredictions = []\n",
    "\n",
    "        for i,method in enumerate(self.firstLayerMethods):\n",
    "            type,model = method.values()\n",
    "            print(\"Training \",type)\n",
    "            if type == \"LGBMR\":\n",
    "                model.fit(X, y, \n",
    "                          eval_set = [eval_set], \n",
    "                          #verbose = 0, \n",
    "                          eval_metric = \"mae\",\n",
    "                          callbacks = [log_evaluation(0,), \n",
    "                                       early_stopping(self.config[\"nb_round_early_stop\"], verbose = False)], \n",
    "                         )\n",
    "            elif type == \"catboost\":\n",
    "                model.fit(X, y, \n",
    "                          eval_set = [eval_set], \n",
    "                          verbose = 0, \n",
    "                          early_stopping_rounds = self.config[\"nb_round_early_stop\"],\n",
    "                         ); \n",
    "\n",
    "            else:\n",
    "                model.fit(X, y)\n",
    "            firstLayerPredictions.append(model.predict(X))\n",
    "        \n",
    "        firstLayerPredictions = np.array(firstLayerPredictions).T\n",
    "        \n",
    "        firstLayerSelection = self.firstLayerSelectionEncoder.fit_transform(np.abs(firstLayerPredictions-np.repeat(y.values[:,np.newaxis],2,1)).argmin(axis=1).reshape(-1,1)).values\n",
    "        \n",
    "        print(\"Training first layer selector\")\n",
    "        \n",
    "        self.firstLayerSelector.fit(X,firstLayerSelection)\n",
    "        \n",
    "        # self.reg.fit(firstLayerPredictions,y)\n",
    "        \n",
    "        return\n",
    "\n",
    "    def predict(self,X):\n",
    "        firstLayerPredictions = []\n",
    "        for i,method in enumerate(self.firstLayerMethods):\n",
    "            type,model = method.values()\n",
    "            firstLayerPredictions.append(model.predict(X))\n",
    "        \n",
    "        firstLayerPredictions = np.array(firstLayerPredictions).T\n",
    "        \n",
    "        firstLayerSelection = self.firstLayerSelector.predict(X)\n",
    "        \n",
    "        return (firstLayerSelection*firstLayerPredictions).sum(axis=1)\n",
    "        \n",
    "        # return self.reg.predict(firstLayerPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['imbalance_auction'] = data['imbalance_size'] * data['imbalance_buy_sell_flag']\n",
    "data['imbalance_auction_proportion_matched'] = data['imbalance_size'] / data['matched_size']\n",
    "data['imbalance_order_book'] = data['bid_size']/(data['bid_size']+data['ask_size'])\n",
    "\n",
    "data['spread'] = data['ask_price'] - data['bid_price']\n",
    "data['mid_price'] = (data['ask_price'] + data['bid_price']) / 2\n",
    "\n",
    "data['bef_300'] = np.where(data['seconds_in_bucket'] <= 300, 1, 0)\n",
    "data['aft_300'] = np.where(data['seconds_in_bucket'] > 300, 1, 0)\n",
    "\n",
    "data.drop(columns=['imbalance_size', 'imbalance_buy_sell_flag', 'row_id', 'time_id'], inplace=True)\n",
    "#data.drop(columns=[\"row_id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T09:44:16.976121Z",
     "iopub.status.busy": "2023-09-24T09:44:16.975307Z",
     "iopub.status.idle": "2023-09-24T09:44:21.096939Z",
     "shell.execute_reply": "2023-09-24T09:44:21.095642Z",
     "shell.execute_reply.started": "2023-09-24T09:44:16.976089Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X = data[~data.target.isna()]\n",
    "y = X.pop('target')\n",
    "\n",
    "# X_bef = X[X['bef_300'] == 1].drop(columns=['far_price', 'near_price'])\n",
    "# X_aft = X[X['aft_300'] == 1]\n",
    "\n",
    "# y_bef = y[y.index.isin(X_bef.index)]\n",
    "# y_aft = y[y.index.isin(X_aft.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 0 Val MAE: 5.879109503910993\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 1 Val MAE: 7.276003555246476\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 2 Val MAE: 6.895819423809661\n",
      "Training  LGBMR\n",
      "Training  catboost\n"
     ]
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost selector with bef/aft split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 0 Val MAE: 6.347937367316545\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 1 Val MAE: 7.918597152981582\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 2 Val MAE: 7.809680726675798\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 3 Val MAE: 7.813109787866368\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 4 Val MAE: 6.6265186352020855\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 5 Val MAE: 6.460874297012216\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 6 Val MAE: 7.200034725962418\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 7 Val MAE: 6.927192232374852\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 8 Val MAE: 6.6083349174891195\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 9 Val MAE: 6.579511262348932\n",
      "Val Score: 7.02918 Â± 0.58163 | model_bef\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([6.347937367316545,\n",
       "  7.918597152981582,\n",
       "  7.809680726675798,\n",
       "  7.813109787866368,\n",
       "  6.6265186352020855,\n",
       "  6.460874297012216,\n",
       "  7.200034725962418,\n",
       "  6.927192232374852,\n",
       "  6.6083349174891195,\n",
       "  6.579511262348932],\n",
       " array([ 0.        ,  0.        ,  0.        , ...,  0.93983515,\n",
       "        -0.09111884, -0.49082114]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X_bef,y_bef,label=\"model_bef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 0 Val MAE: 5.328784933055805\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 1 Val MAE: 6.511028192774758\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 2 Val MAE: 6.487829942557861\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 3 Val MAE: 6.478314129753692\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 4 Val MAE: 5.543599931129056\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 5 Val MAE: 5.46387383115327\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 6 Val MAE: 5.718727959026511\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 7 Val MAE: 5.554874339162555\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 8 Val MAE: 5.1658269768812355\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 9 Val MAE: 5.019251417090166\n",
      "Val Score: 5.72721 Â± 0.53526 | model_aft\n"
     ]
    }
   ],
   "source": [
    "result_aft = cross_val_score(MetaModel,X_aft,y_aft,label=\"model_aft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression selector with bef/aft split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 0 Val MAE: 6.931939494240654\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 1 Val MAE: 8.436610870054755\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 2 Val MAE: 10.533642104364167\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 3 Val MAE: 7.981769462337933\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 4 Val MAE: 6.73263052222328\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 5 Val MAE: 6.558399040955649\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 6 Val MAE: 7.244063121948457\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 7 Val MAE: 7.073760209161333\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 8 Val MAE: 6.744928129936018\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 9 Val MAE: 6.69553079590666\n",
      "Val Score: 7.49333 Â± 1.16510 | model_bef\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([6.931939494240654,\n",
       "  8.436610870054755,\n",
       "  10.533642104364167,\n",
       "  7.981769462337933,\n",
       "  6.73263052222328,\n",
       "  6.558399040955649,\n",
       "  7.244063121948457,\n",
       "  7.073760209161333,\n",
       "  6.744928129936018,\n",
       "  6.69553079590666],\n",
       " array([ 0.        ,  0.        ,  0.        , ...,  4.39555036,\n",
       "         0.09355896, -0.47424669]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X_bef,y_bef,label=\"model_bef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 0 Val MAE: 5.641635805992633\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 1 Val MAE: 6.755317249491351\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 2 Val MAE: 8.344468721725047\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 3 Val MAE: 6.917156508682197\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 4 Val MAE: 5.652181431725709\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 5 Val MAE: 5.5228968653165795\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 6 Val MAE: 5.789824158269713\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 7 Val MAE: 6.024225192062919\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 8 Val MAE: 5.193028676768116\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 9 Val MAE: 5.209143437097536\n",
      "Val Score: 6.10499 Â± 0.92717 | model_aft\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5.641635805992633,\n",
       "  6.755317249491351,\n",
       "  8.344468721725047,\n",
       "  6.917156508682197,\n",
       "  5.652181431725709,\n",
       "  5.5228968653165795,\n",
       "  5.789824158269713,\n",
       "  6.024225192062919,\n",
       "  5.193028676768116,\n",
       "  5.209143437097536],\n",
       " array([ 0.        ,  0.        ,  0.        , ..., -0.29073928,\n",
       "         2.18888491, -5.44373671]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X_aft,y_aft,label=\"model_aft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression selector without bef/aft split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 0 Val MAE: 6.168401439219442\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 1 Val MAE: 7.642852021352264\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 2 Val MAE: 7.333824459341764\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 3 Val MAE: 7.275478509434792\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 4 Val MAE: 6.210999961521283\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 5 Val MAE: 6.078875795156375\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 6 Val MAE: 6.564586806006145\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 7 Val MAE: 6.359768607781469\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 8 Val MAE: 6.057330742338905\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Fold 9 Val MAE: 5.89008601467084\n",
      "Val Score: 6.55822 Â± 0.59426 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([6.168401439219442,\n",
       "  7.642852021352264,\n",
       "  7.333824459341764,\n",
       "  7.275478509434792,\n",
       "  6.210999961521283,\n",
       "  6.078875795156375,\n",
       "  6.564586806006145,\n",
       "  6.359768607781469,\n",
       "  6.057330742338905,\n",
       "  5.89008601467084],\n",
       " array([ 0.        ,  0.        ,  0.        , ...,  1.07484548,\n",
       "         1.72683925, -3.59432684]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost selector without bef/aft split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 0 Val MAE: 5.894938568205118\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 1 Val MAE: 7.3087571695506295\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 2 Val MAE: 6.932196830282457\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 3 Val MAE: 7.2086890429742825\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 4 Val MAE: 6.143983727497267\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 5 Val MAE: 6.029022844577131\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 6 Val MAE: 6.544286466705665\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 7 Val MAE: 6.292429203995975\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 8 Val MAE: 5.989033922078409\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 9 Val MAE: 5.8627754066657785\n",
      "Val Score: 6.42061 Â± 0.52028 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5.894938568205118,\n",
       "  7.3087571695506295,\n",
       "  6.932196830282457,\n",
       "  7.2086890429742825,\n",
       "  6.143983727497267,\n",
       "  6.029022844577131,\n",
       "  6.544286466705665,\n",
       "  6.292429203995975,\n",
       "  5.989033922078409,\n",
       "  5.8627754066657785],\n",
       " array([ 0.        ,  0.        ,  0.        , ...,  0.63031969,\n",
       "         1.07024192, -2.05362575]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost selector, without b/a split, without feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 0 Val MAE: 5.911270404343734\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 1 Val MAE: 7.32854370625557\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 2 Val MAE: 6.9590646134574365\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 3 Val MAE: 7.225255301378903\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 4 Val MAE: 6.166512106745125\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 5 Val MAE: 6.047953904726102\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 6 Val MAE: 6.55426731617956\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 7 Val MAE: 6.300287113531595\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 8 Val MAE: 6.002972059837637\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 9 Val MAE: 5.876055236998791\n",
      "Val Score: 6.43722 Â± 0.52203 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5.911270404343734,\n",
       "  7.32854370625557,\n",
       "  6.9590646134574365,\n",
       "  7.225255301378903,\n",
       "  6.166512106745125,\n",
       "  6.047953904726102,\n",
       "  6.55426731617956,\n",
       "  6.300287113531595,\n",
       "  6.002972059837637,\n",
       "  5.876055236998791],\n",
       " array([ 0.        ,  0.        ,  0.        , ...,  0.53036643,\n",
       "         1.68544934, -2.24955026]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_baseline = pd.read_parquet(\"./Baseline/BaselineData/XTrIntCmpNewFtre.parquet\")\n",
    "y_baseline = pd.read_parquet(\"./Baseline/BaselineData/Ytrain.parquet\")[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 0 Val MAE: 5.858464297078814\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 1 Val MAE: 7.241476161973192\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 2 Val MAE: 6.871425577293039\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 3 Val MAE: 7.176109464546702\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cross_val_score(MetaModel,X_baseline,y_baseline)\n",
      "\u001b[1;32m/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m X_val\u001b[39m.\u001b[39mfillna(mu)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#train model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m#make predictions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# train_preds = model.predict(X_train)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m val_preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_val)\n",
      "\u001b[1;32m/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m firstLayerSelection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfirstLayerSelectionEncoder\u001b[39m.\u001b[39mfit_transform(np\u001b[39m.\u001b[39mabs(firstLayerPredictions\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mrepeat(y\u001b[39m.\u001b[39mvalues[:,np\u001b[39m.\u001b[39mnewaxis],\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39margmin(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining first layer selector\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfirstLayerSelector\u001b[39m.\u001b[39;49mfit(X,firstLayerSelection)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# self.reg.fit(firstLayerPredictions,y)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/paulbourcereau/Projects/OptiverTATC/meta-model-cv.ipynb#X31sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/catboost/core.py:5100\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5097\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5098\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5100\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[1;32m   5101\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[1;32m   5102\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[1;32m   5103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cross_val_score(MetaModel,X_baseline,y_baseline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
