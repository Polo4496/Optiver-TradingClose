{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014282,
     "end_time": "2023-06-03T01:46:16.695936",
     "exception": false,
     "start_time": "2023-06-03T01:46:16.681654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading Libraries and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-24T09:43:44.600967Z",
     "iopub.status.busy": "2023-09-24T09:43:44.600229Z",
     "iopub.status.idle": "2023-09-24T09:43:50.495944Z",
     "shell.execute_reply": "2023-09-24T09:43:50.494498Z",
     "shell.execute_reply.started": "2023-09-24T09:43:44.600930Z"
    },
    "papermill": {
     "duration": 4.795021,
     "end_time": "2023-06-03T01:46:36.791162",
     "exception": false,
     "start_time": "2023-06-03T01:46:31.996141",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "set_config(transform_output = 'pandas')\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-09-24T09:43:50.500527Z",
     "iopub.status.busy": "2023-09-24T09:43:50.499127Z",
     "iopub.status.idle": "2023-09-24T09:44:16.378234Z",
     "shell.execute_reply": "2023-09-24T09:44:16.376885Z",
     "shell.execute_reply.started": "2023-09-24T09:43:50.500463Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "medianVol = pd.read_csv(\"medianVolV2.csv\")\n",
    "data = data.merge(medianVol, how = \"left\", on = \"stock_id\")\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    features = ['seconds_in_bucket', 'imbalance_buy_sell_flag',\n",
    "                'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n",
    "                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap',\n",
    "                'imb_s1', 'imb_s2', 'overall_medvol', 'first5min_medvol', 'last5min_medvol']\n",
    "    \n",
    "    df['imb_s1'] = df.eval('(bid_size-ask_size)/(bid_size+ask_size)')\n",
    "    df['imb_s2'] = df.eval('(imbalance_size-matched_size)/(matched_size+imbalance_size)')\n",
    "    \n",
    "    df['mid_price'] = (df['ask_price'] + df['bid_price']) / 2\n",
    "    \n",
    "    prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap', 'mid_price']\n",
    "    \n",
    "    for i,a in enumerate(prices):\n",
    "        for j,b in enumerate(prices):\n",
    "            if i>j:\n",
    "                df[f'{a}_{b}_imb'] = df.eval(f'({a}-{b})/({a}+{b})')\n",
    "                features.append(f'{a}_{b}_imb')    \n",
    "                    \n",
    "    for i,a in enumerate(prices):\n",
    "        for j,b in enumerate(prices):\n",
    "            for k,c in enumerate(prices):\n",
    "                if i>j and j>k:\n",
    "                    max_ = df[[a,b,c]].max(axis=1)\n",
    "                    min_ = df[[a,b,c]].min(axis=1)\n",
    "                    mid_ = df[[a,b,c]].sum(axis=1)-min_-max_\n",
    "\n",
    "                    df[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "                    features.append(f'{a}_{b}_{c}_imb2')\n",
    "    \n",
    "    return df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10)\n",
    "models_reg = []\n",
    "models_classif = []\n",
    "\n",
    "def cross_val_score_reg(X, y, cv = cv):\n",
    "    val_scores = []\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "\n",
    "        model_reg = MetaModelReg()\n",
    "        model_reg.fit(X_train, y_train)\n",
    "        models_reg.append(model_reg)\n",
    "        \n",
    "        val_preds = model_reg.predict(X_val)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        print(\"Fold\", fold, \"Val MAE:\", val_score)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} Â± {np.std(val_scores):.5f}')\n",
    "\n",
    "def cross_val_score_classif(X, y, cv = cv):\n",
    "    preds_not_null, good_preds_not_null = [], []\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        model_classif = MetaModelClassif()\n",
    "        model_classif.fit(X_train, y_train)\n",
    "        models_classif.append(model_classif)\n",
    "\n",
    "        val_preds = model_classif.predict(X_val)\n",
    "        pred_not_null, good_pred_not_null = evaluate(val_preds, y_val)\n",
    "        \n",
    "        print(\"Fold\", fold, \"----------\")\n",
    "        print(\"Pred != 0:\", pred_not_null)\n",
    "        print(\"Good Pred | Pred != 0:\", good_pred_not_null)\n",
    "        print(\"Good Pred:\", pred_not_null*good_pred_not_null)\n",
    "        \n",
    "        preds_not_null.append(pred_not_null)\n",
    "        good_preds_not_null.append(good_pred_not_null)\n",
    "        \n",
    "    print(\"--------------------\")\n",
    "    print(\"Mean Pred != 0:\", np.mean(preds_not_null))\n",
    "    print(\"Mean Good Pred | Pred != 0:\", np.mean(good_preds_not_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T09:44:44.962033Z",
     "iopub.status.busy": "2023-09-24T09:44:44.961514Z",
     "iopub.status.idle": "2023-09-24T09:44:44.977754Z",
     "shell.execute_reply": "2023-09-24T09:44:44.976315Z",
     "shell.execute_reply.started": "2023-09-24T09:44:44.961984Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetaModelReg : \n",
    "    def __init__(self):\n",
    "        self.firstLayerMethods = [\n",
    "            {\n",
    "                \"type\":\"LGBMR\",\n",
    "                \"model\":LGBMRegressor(random_state=seed, objective=\"mae\", verbose=0, n_estimators=50, device='GPU')\n",
    "            },\n",
    "            {\n",
    "                \"type\":\"catboost\",\n",
    "                \"model\":CatBoostRegressor(random_seed=seed, objective=\"MAE\", n_estimators=50, verbose=0)\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        self.firstLayerSelector = LGBMRegressor(random_state=seed, objective=\"mae\", verbose=0, n_estimators=100, device='GPU')\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        firstLayerPredictions = []\n",
    "\n",
    "        for i, method in enumerate(self.firstLayerMethods):\n",
    "            type, model = method.values()\n",
    "            print(\"Training \", type)\n",
    "            model.fit(X, y)\n",
    "            firstLayerPredictions.append(model.predict(X))\n",
    "        \n",
    "        print(\"Training first layer selector\")\n",
    "        \n",
    "        # y = a*x + b*z -> a = (y-z)/(x-z)\n",
    "        a = (y-firstLayerPredictions[1])/(firstLayerPredictions[0]-firstLayerPredictions[1])\n",
    "        a = np.where(a > 1, 1, a)\n",
    "        a = np.where(a < 0, 0, a)\n",
    "        \n",
    "        self.firstLayerSelector.fit(X, a)\n",
    "        \n",
    "        self.y_m = y.mean()\n",
    "        \n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        firstLayerPredictions = []\n",
    "        for i, method in enumerate(self.firstLayerMethods):\n",
    "            type, model = method.values()\n",
    "            firstLayerPredictions.append(model.predict(X))\n",
    "        \n",
    "        a = self.firstLayerSelector.predict(X)\n",
    "        \n",
    "        firstLayerSelection = np.array([a, 1-a]).T\n",
    "        firstLayerPredictions = np.array(firstLayerPredictions).T\n",
    "        \n",
    "        prediction = (firstLayerPredictions * firstLayerSelection).sum(axis=1)\n",
    "        \n",
    "        # Mean change\n",
    "        prediction += self.y_m - np.mean(prediction)\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaModelClassif : \n",
    "    def __init__(self):\n",
    "        self.models = [\n",
    "            {\n",
    "                \"type\": \"LGBM Classifier\",\n",
    "                \"model\": LGBMClassifier(random_seed=seed, n_estimators=400, verbose=0)\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"CatBoost Classifier\",\n",
    "                \"model\": CatBoostClassifier(random_seed=seed, n_estimators=400, verbose=0)\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        y = np.where(y >= 0, 1, 0)\n",
    "        \n",
    "        for i, method in enumerate(self.models):\n",
    "            type, model = method.values()\n",
    "            print(\"Training \", type)\n",
    "            model.fit(X, y)\n",
    "            \n",
    "        return\n",
    "\n",
    "    def predict(self, X):\n",
    "        models_pred_class = []\n",
    "        models_pred_proba = []\n",
    "        \n",
    "        for i, method in enumerate(self.models):\n",
    "            type, model = method.values()\n",
    "            models_pred_class.append(model.predict(X))\n",
    "            models_pred_proba.append(np.max(model.predict_proba(X), axis=1))\n",
    "        \n",
    "        pred_class = np.mean(np.array(models_pred_class).T, axis=1)\n",
    "        pred_proba = np.max(np.array(models_pred_proba).T, axis=1)\n",
    "            \n",
    "        prediction = np.where((pred_class == 1) & (pred_proba > 0.57), 1, 0)\n",
    "        prediction = np.where((pred_class == 0) & (pred_proba > 0.57), -1, prediction)\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred, value):\n",
    "    pred_not_null = len(value[pred!=0])/len(value)\n",
    "    good_pred_not_null = len(value[(np.sign(value) == pred) & (pred!=0)])/len(value[pred!=0])\n",
    "    return pred_not_null, good_pred_not_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[~data.target.isna()]\n",
    "y = X.pop('target')\n",
    "X = generate_features(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mu = X_train.mean()\n",
    "X_train.fillna(mu, inplace=True)\n",
    "X_test.fillna(mu, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T09:44:16.976121Z",
     "iopub.status.busy": "2023-09-24T09:44:16.975307Z",
     "iopub.status.idle": "2023-09-24T09:44:21.096939Z",
     "shell.execute_reply": "2023-09-24T09:44:21.095642Z",
     "shell.execute_reply.started": "2023-09-24T09:44:16.976089Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBM Classifier\n",
      "Training  CatBoost Classifier\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "MAE: 6.265823436717951\n"
     ]
    }
   ],
   "source": [
    "# nb_estimators=100 for classifier\n",
    "model_classif = MetaModelClassif()\n",
    "model_classif.fit(X_train, y_train)\n",
    "X_train['sign'] = model_classif.predict(X_train)\n",
    "\n",
    "model_reg = MetaModelReg()\n",
    "model_reg.fit(X_train, y_train)\n",
    "\n",
    "X_test['sign'] = model_classif.predict(X_test)\n",
    "pred = model_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE:\", np.mean(np.abs(pred-y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-24T09:44:16.976121Z",
     "iopub.status.busy": "2023-09-24T09:44:16.975307Z",
     "iopub.status.idle": "2023-09-24T09:44:21.096939Z",
     "shell.execute_reply": "2023-09-24T09:44:21.095642Z",
     "shell.execute_reply.started": "2023-09-24T09:44:16.976089Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBM Classifier\n",
      "Training  CatBoost Classifier\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "MAE: 6.256174230379108\n"
     ]
    }
   ],
   "source": [
    "# nb_estimators=400 for classifier\n",
    "model_classif = MetaModelClassif()\n",
    "model_classif.fit(X_train, y_train)\n",
    "X_train['sign'] = model_classif.predict(X_train)\n",
    "\n",
    "model_reg = MetaModelReg()\n",
    "model_reg.fit(X_train, y_train)\n",
    "\n",
    "X_test['sign'] = model_classif.predict(X_test)\n",
    "pred = model_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE:\", np.mean(np.abs(pred-y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred != 0: 0.37096478672771055\n",
      "Good Pred | Pred != 0: 0.6248441651515256\n",
      "Good Pred: 0.23179518246349007\n",
      "----------\n",
      "Pred != 0: 0.37076953783761113\n",
      "Good Pred | Pred != 0: 0.6213033078110152\n",
      "Good Pred: 0.23036034029406915\n"
     ]
    }
   ],
   "source": [
    "pred_not_null, good_pred_not_null = evaluate(X_train['sign'], y_train)\n",
    "print(\"Pred != 0:\", pred_not_null)\n",
    "print(\"Good Pred | Pred != 0:\", good_pred_not_null)\n",
    "print(\"Good Pred:\", pred_not_null*good_pred_not_null)\n",
    "print(\"----------\")\n",
    "pred_not_null, good_pred_not_null = evaluate(X_test['sign'], y_test)\n",
    "print(\"Pred != 0:\", pred_not_null)\n",
    "print(\"Good Pred | Pred != 0:\", good_pred_not_null)\n",
    "print(\"Good Pred:\", pred_not_null*good_pred_not_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With CV on Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "mu = X_train.mean()\n",
    "X_train.fillna(mu, inplace=True)\n",
    "X_test.fillna(mu, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean = np.mean([model.predict(X_train) for model in models_classif], axis=0)\n",
    "pred = np.where(pred_mean > 0.2, 1, 0)\n",
    "X_train['sign'] = np.where(pred_mean < -0.2, -1, pred)\n",
    "\n",
    "pred_mean = np.mean([model.predict(X_test) for model in models_classif], axis=0)\n",
    "pred = np.where(pred_mean > 0.2, 1, 0)\n",
    "X_test['sign'] = np.where(pred_mean < -0.2, -1, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred != 0: 0.4158509734036172\n",
      "Good Pred | Pred != 0: 0.6202543268314944\n",
      "Good Pred: 0.25793336557068225\n",
      "----------\n",
      "Pred != 0: 0.41546480918481576\n",
      "Good Pred | Pred != 0: 0.6165000076587485\n",
      "Good Pred: 0.2561340580443794\n"
     ]
    }
   ],
   "source": [
    "pred_not_null, good_pred_not_null = evaluate(X_train['sign'], y_train)\n",
    "print(\"Pred != 0:\", pred_not_null)\n",
    "print(\"Good Pred | Pred != 0:\", good_pred_not_null)\n",
    "print(\"Good Pred:\", pred_not_null*good_pred_not_null)\n",
    "print(\"----------\")\n",
    "pred_not_null, good_pred_not_null = evaluate(X_test['sign'], y_test)\n",
    "print(\"Pred != 0:\", pred_not_null)\n",
    "print(\"Good Pred | Pred != 0:\", good_pred_not_null)\n",
    "print(\"Good Pred:\", pred_not_null*good_pred_not_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "MAE: 6.263797957983771\n"
     ]
    }
   ],
   "source": [
    "model_reg = MetaModelReg()\n",
    "model_reg.fit(X_train, y_train)\n",
    "pred = model_reg.predict(X_test)\n",
    "\n",
    "print(\"MAE:\", np.mean(np.abs(pred-y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With CV on Classifier & Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 0 Val MAE: 6.254954237074795\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 1 Val MAE: 6.279565550756611\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 2 Val MAE: 6.266214868364509\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 3 Val MAE: 6.271564502268674\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 4 Val MAE: 6.272215527258818\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 5 Val MAE: 6.26350170347782\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 6 Val MAE: 6.2572012953523135\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 7 Val MAE: 6.238689633136678\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 8 Val MAE: 6.28545893455102\n",
      "Training  LGBMR\n",
      "Training  catboost\n",
      "Training first layer selector\n",
      "Fold 9 Val MAE: 6.261338069601696\n",
      "Val Score: 6.26507 Â± 0.01264\n"
     ]
    }
   ],
   "source": [
    "cross_val_score_reg(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.263430775828357\n"
     ]
    }
   ],
   "source": [
    "pred = np.mean([model.predict(X_test) for model in models_reg], axis=0)\n",
    "print(\"MAE:\", np.mean(np.abs(pred-y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
